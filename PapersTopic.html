<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<HTML>
<HEAD>
    <TITLE>PapersTopic</TITLE>
    <script src="linkmapping.js"></script>
</HEAD>

<BODY>

<font size="4" face="Times">


<H1>Research Topics</H1>
The most recently active research topics are listed first.

<ol>

<li><H3>Reaction-diffusion equations and wave front propagation in random media.</H3>
Molecular motors, which are biological molecular machines that are the essential 
agents of movement in living organisms, can be modeled as diffusion particles 
traveling in a designated track. To model the environment in which the 
fluctuations due to thermal noise are significant, I have been considering 
the traveling of these motors in a narrow random channel. Under the asymptotic 
when the channel width is thin, I derive the limiting process as a diffusion 
process on a graph (see the work [1] below).
Furthermore, I introduce in [2] a reaction-diffusion equation in random media, 
which models the change in space and time of the concentration of these motors. 
By making use of large deviations theory for diffusion processes in random media, 
I derive the wave front propagation formula for the corresponding reaction-diffusion 
system. 
<P>
In the work [3] done in the year 2019, we consider the asymptotic wave speed for 
Fisher-Kolmogorov-Petrovskii-Piscounov (FKPP) type
reaction-diffusion equations on a class of infinite random metric trees.
We show that a travelling wavefront emerges and we quantify it via a variational formula
involving the random branching degrees and the random branch lengths of the tree. Here
our key idea is to project the Brownian motion on the tree onto a one-dimensional
axis along the direction of the wave propagation. The projected process is
a multi-skewed Brownian motion, with skewness and interface sets that encode 
the metric structure of the tree.
Combined with analytic arguments based on the Feynman-Kac formula, this idea
connects our analysis of the wavefront propagation to the Large Deviations Principle (LDP)
of the multi-skewed Brownian motion with random skewness and random interface set.
<P>
A recent work [4] done in 2025 resolves the small reaction rate case left in [3] as well as 
an open problem in the classical monograph 
"Functional Integration and Partial Differential Equations" 
(Princeton University Press, 1985) by Freidlin (Section 7.6, Remark 4, pp.524-525). 
Here we consider the wave propagation for a reaction-diffusion equation on the real line, 
with a random drift and FKPP type nonlinear reaction. 
We show that when the average drift is positive, the asymptotic wave fronts propagating to 
the positive and negative directions are both pushed in the negative direction, 
leading to the possibility that both wave fronts propagate toward negative infinity. 
Our probabilistic arguments also reveal the underlying physical mechanism 
of the wave fronts formation: the drift acts as an external field that shifts 
the (quenched) free-energy reference level without altering the intrinsic 
fluctuation structure of the system.
<H4>Papers.</H4>
[4] Guan, D., He, H., <b>Hu, W.</b>, Yang, J., Wave propagation for 1-dimensional reaction-diffusion equation with nonzero random drift.
<A HREF="https://arxiv.org/abs/2512.21906">[arXiv]</A>
<P>
[3] Fan, W., <b>Hu, W.</b>, Terlov, G., Wave propagation for reaction-diffusion equations on infinite random trees.
<i>Communications in Mathematical Physics</i>,
<b>384</b>, Issue 1, April 2021, pages 109-163. 
<A HREF="https://arxiv.org/abs/1907.12962">[arXiv]</A>
<A HREF="https://link.springer.com/article/10.1007%2Fs00220-021-04085-z">[journal paper]</A>
<P>
[2] Freidlin, M., <b>Hu, W.</b>, Wave front propagation for a reaction-diffusion equation in narrow random channels.
<i>Nonlinearity</i>, <b>26</b>, 8, 2013, pp. 2333-2356.
<A HREF="http://arxiv.org/abs/1303.6943">[arXiv]</A>
<A HREF="http://iopscience.iop.org/0951-7715/26/8/2333/">[journal paper]</A>
<P>
[1] Freidlin, M., <b>Hu, W.</b>, On diffusion in narrow random channels.
<i>Journal of Statistical Physics</i>, <b>152</b>, 2013, pp. 136-158.
<A HREF="http://arxiv.org/abs/1210.5226">[arXiv]</A>
<A HREF="http://link.springer.com/article/10.1007%2Fs10955-013-0763-3">[journal paper]</A>
<H4>Slides.</H4>
[2] <A HREF="slides_wave-tree.pdf">
Wave propagation for reaction-diffusion equation on infinite random trees</A>.
<P>
[1] <A HREF="slides_On_diffusion_and_wave_front_propagation_in_narrow_random_channels.pdf">
Diffusion and wave front propagation in narrow random channels</A>.
</li>


<li><H3>Markov Decision Processes and Reinforcement Learning 
    applied to Microgrid and Manufacturing Systems.</H3>
Several real-world applications of Markov Decision Process (MDP) and 
Reinforcement Learning are considered under this project.
In [1], we propose a joint dynamic decision-making model for the optimal 
control for both manufacturing system and
onsite generation system via MDP and a neural network integrated reinforcement 
learning algorithm.
In [2] a real-time decision-making model is proposed for the
electric vehicle (EV) aggregator to dynamically control the energy flow 
between the grid and
each individual EV in the aggregated group.
<P>
In the work [3] finished in 2020, we propose a joint dynamic 
control model of microgrids and manufacturing systems using
Markov Decision Process (MDP) to identify an optimal control 
strategy for both microgrid components and
manufacturing system so that the energy cost for production 
can be minimized without sacrificing production throughput.
The proposed MDP model has a high dimensional state/action 
space and is complicated in that the state and action spaces
have both discrete and continuous parts and are intertwined 
through constraints. To resolve these challenges, a
novel reinforcement learning algorithm that leverages both 
on-policy temporal difference control (TD-control) and
deterministic policy gradient (DPG) algorithms is proposed. 
In this algorithm, the values of discrete decision actions
are learned through neural network integrated temporal 
difference iteration, while the parameterized values of continuous
actions are learned from deterministic policy gradients. 
The constraints are then addressed via proximal projection
operators at the policy gradient updates. Experiments for 
a manufacturing system with an onsite microgrid with renewable
sources have been implemented to identify optimal control actions 
for both manufacturing system and microgrid
components towards cost optimality. The experimental results 
show the effectiveness of combining TD control
and policy gradient methodologies in addressing the "curse of dimensionality" 
in dynamic decision-making
with high dimensional and complicated state and action spaces. 
We refer to <A HREF="slides_RL-Manufacturing.pdf">
this slide</A>.
<H4>Papers.</H4>
[3] Yang, J., Sun, Z., <b>Hu, W.</b>, Steimeister, L., Joint Control of Manufacturing and Onsite Microgrid System via Novel
Neural-Network Integrated Reinforcement Learning Algorithms.
<i>Applied Energy</i>, Volume <b>315</b>, 1 June 2022, 118982.
<A HREF="paper_Joint_Control_of_Manufacturing_and_Onsite_Microgrid_System_via_Novel_Neural_Network_Integrated_Reinforcement_Learning_Algorithms.pdf">[manuscript]</A>
<A HREF="https://www.sciencedirect.com/science/article/pii/S0306261922003919?utm_campaign=STMJ_AUTH_SERV_PUBLISHED&utm_medium=email&utm_acid=128692634&SIS_ID=&dgcid=STMJ_AUTH_SERV_PUBLISHED&CMX_ID=&utm_in=DM248380&utm_source=AC_">[journal paper]</A>
<A HREF="https://github.com/huwenqing0606/RL-manufacturing">[source code]</A>
<P>
[2] Islam, Md M., Zhong, X., Sun, Z., Xiong, H., <b>Hu, W.</b>,
Real-Time Frequency Regulation Using Aggregated Electric Vehicles in Smart Grid.
<i>Computers & Industrial Engineering</i>, Volume <b>134</b>, August 2019, pages 11-26.
<A HREF="https://www.sciencedirect.com/science/article/abs/pii/S036083521930292X?via%3Dihub">[journal paper]</A>
<P>
[1] <b>Hu, W.</b>, Sun, Z., Zhang, Y., Li, Y., Joint Manufacturing and Onsite Microgrid
System Control Using Markov Decision Process and Neural Network Integrated Reinforcement Learning.
<i>ICPR 2019 (the 25th International Conference on Production Research), Chicago, Illinois, USA, August 10-14, 2019</i>.
<A HREF="https://www.sciencedirect.com/science/article/pii/S2351978920304121">[conference paper]</A>
<H4>Slides.</H4>
[1] <A HREF="slides_RL-Manufacturing.pdf">
Joint Control of Manufacturing and Onsite Microgrid System via Markov Decision Processes and Reinforcement Learning</A>.
</li>


<li><H3>Zero-Knowledge Proofs applied to Blockchain Systems and Virtual Machines.</H3>
Zero-Knowledge Proofs (ZKPs) are interactive protocols where a prover can convince 
a verifier they know a secret without revealing it. The leap to Succinct 
Non-interactive Arguments of Knowledge (SNARKs) enabled very short proofs 
and one-message communication. This has become a core component of Layer-2 
scaling solutions (rollups) for blockchain systems like Ethereum, 
leading to the so called zero-knowledge 
Ethereum Virtual Machine 
(<A HREF="https://vitalik.eth.limo/general/2022/08/04/zkevm.html">zkEVM</A>). For example, zk-Rollups bundle 
many transactions off-chain, then publish a SNARK proof on-chain that 
the rollup state transition was correct. This results in a relatively low, 
fixed on-chain verification cost, instead of processing each 
transaction individually on-chain.
<P>
In a recent paper [1], we propose a novel zero-knowledge Virtual Machine (zkVM) 
framework. Unlike 
<A HREF="https://github.com/privacy-ethereum/zkevm-circuits">previous proof systems</A> 
following the sequential execution of opcodes, here we break 
the execution of arbitrary code into segments (at opcode and basic-block levels) 
and use data-parallel circuits with dynamic duplication of identical segments. 
A key technical tool is our use of an asymmetric GKR protocol 
(Goldwasser-Kalai-Rothblum) scheme, pairing a non-uniform prover 
and a uniform verifier to handle dynamic-length data-parallel circuits. 
This allows them to commit only to the circuit's input and output 
(in contrast to many <A HREF="https://eprint.iacr.org/2019/953.pdf">PLONK</A>-style 
proofs where the prover must commit to all internal wires). 
<H4>Papers.</H4>
[1] Liu, T., Zhang, Z., Zhang, Y., <b>Hu, W.</b>, Zhang, Y., <i>Ceno</i>: Non-uniform, Segment and Parallel Zero-knowledge Virtual Machine. 
<i>Journal of Cryptology</i>, <b>38</b>, 17(2025).
<A HREF="https://eprint.iacr.org/2024/387">[Cryptology ePrint Archive]</A>
<A HREF="https://link.springer.com/article/10.1007/s00145-024-09533-2">[journal paper]</A>
<A HREF="https://github.com/scroll-tech/ceno">[open-source project code]</A>
<H4>Expository Notes.</H4>
[3] Documentations of zkEVM circuits: 
<A HREF="https://hackmd.io/@dieGzUCgSGmRZFQ7SDxXCA/BJF7RZad2">EVM Circuit</A>,
<A HREF="https://hackmd.io/@dieGzUCgSGmRZFQ7SDxXCA/HkVuEMTOn">Bytecode Circuit</A>,
<A HREF="https://hackmd.io/@dieGzUCgSGmRZFQ7SDxXCA/B1ePCba_2">State Circuit</A>,
<A HREF="https://hackmd.io/@dieGzUCgSGmRZFQ7SDxXCA/B1454z6_3">Transaction Circuit</A>,
<A HREF="https://hackmd.io/@dieGzUCgSGmRZFQ7SDxXCA/rJmoKkcO3">MPT Circuit</A>,
<A HREF="https://hackmd.io/@dieGzUCgSGmRZFQ7SDxXCA/rk6AZvlo2">Signature Circuit</A>,
<A HREF="https://hackmd.io/@dieGzUCgSGmRZFQ7SDxXCA/H1yLFYr9h">Public Input Circuit</A>,
<A HREF="https://hackmd.io/@dieGzUCgSGmRZFQ7SDxXCA/H1vMF0_u2">Keccak Circuit</A>,
<A HREF="https://hackmd.io/@dieGzUCgSGmRZFQ7SDxXCA/SyHlJiRin">Modexp Circuit</A>.
<P>
[2] Summary of some recent algorithms related to Zero-Knowledge Proofs. 
<A HREF="https://drive.google.com/file/d/1fHyp6gvpZBB9kMHgib33_vjH6fekucdd/view?usp=sharing">Notes</A>.
<P>
[1] Notes on Cryptographic Zero-Knowledge Proofs (based on Justin Thaler's textbook <i>Proofs, Arguments and Zero-Knowledge</i>).
<A HREF="lectures_Justin-ZKbook_notes.pdf">Notes</A>.
</li>


<li><H3>Intepretable Neural Networks.</H3>
(to be revised) 
Subspace Indexing with Interpolation (SIM-I) on Stiefel and Grassmann manifolds is proposed in [1]. 
Given a partition of some original high-dimensional data set, SIM-I is constructed via two steps: 
in the first step we build linear affinity-aware subspace models based on each partition; 
in the second step we interpolate between several adjacent linear subspace models constructed 
in the first step using the “center of mass” calculation on Stiefel and Grassmann manifolds. 
Through these two steps, SIM-I builds a globally nonlinear and smoothly regularized 
low-dimensional embedding model of the original data set. Furthermore, given sufficiently 
many training samples on the data manifold either labelled by some pre-trained learning model 
such as Deep Neural Networks (DNNs) or provided with original natural labels, 
we first apply SIM-I on this data set and then perform nearest-neighbor classification 
on the resulting low-dimensional embedding. This helps us to build a Lightweight Inference Engine (LIE) 
carrying similar level of feature extraction by the pre-trained learning model. For DNNs, such LIE 
can be interpreted as some (nonstandard) shallow neural network with a wide first hidden layer. 
From this perspective, SIM-I provides a way to exchange deep network for wide but shallow ones 
and may provide some new insights to interpret DNNs.
<H4>Papers.</H4>
[1] <b>Hu, W.</b>, Jiang, T., Kathariya, B., Abrol, V., Zhang, J., Li, Z., Subspace Interpolation and Indexing on Stiefel and Grassmann Manifolds as a Lightweight Inference Engine.
<i>IEEE Big Data 2023 (2023 IEEE International Conference on Big Data), Sorrento, Italy, December 15-18, 2023</i>.
(Acceptance Rate: 92/526=17.5%)
<A HREF="https://ieeexplore.ieee.org/document/10386432">[conference paper]</A>
<A HREF="https://github.com/huwenqing0606/SubspaceIndexing_StiefelGrassmann/blob/master/BigD401_CameraReady.pdf">[manuscript]</A>
<A HREF="https://github.com/huwenqing0606/SubspaceIndexing_StiefelGrassmann">[source code]</A>
<A HREF="https://www.youtube.com/watch?v=MFwBrv3gcW0">[video]</A>
<H4>Slides.</H4>
[1] <A HREF="slides_Subspace_Indexing.pdf">
Subspace Interpolation and Indexing on Stiefel and Grassmann Manifolds as a Lightweight Inference Engine</A>.
</li>


<li><H3>Variance-Reduced Stochastic Gradient Methods for Compositional Optimization Problems.</H3>
Compositional Optimization are a class of optimization problems that appear very often in many machine learning applications,
such as portfolio management, reinforcement learning and stochastic neighbor embedding. The goal is to find the minimizer of the
composition of expectations of two stochastic functions, and therefore is more challenging to optimize than vanilla stochastic
optimization problem. Under this project, some investigations are made on variance-reduced stochastic gradient methods
that solve compositional optimization problems. In [1] a team of W. Hu's collaborators
(W. Hu participated in the writing of a very initial draft
regarding this problem and thus the list of authors include W. Hu himself)
proposed a compositional version of StochAstic Recursive grAdient algoritHm (SARAH-Compositional)
and proved that it achieved the best known Incremental First-order Oracle (IFO) complexity upper bound (at the time of publication).
Unfortunately the complete <A HREF="https://arxiv.org/abs/1912.13515">arXiv</A> version of this work contains a gap in the proof
found by W. Hu and he feels that he cannot fill it in.
In a recent work [2] done in 2020, H. Yuan brought W. Hu's attention to the
STOchastic Recursive Momentum method, and based on this, the two authors propose the STORM-Compositional optimization
that introduces the momentum term in the compositional gradient updates. STORM-Compositional is thus operating the stochastic recursive
variance-reduced compositional gradients in an exponential-moving average way. STORM-Compositional avoids
the missing gap in SARAH-Compositional (see the complete <A HREF="https://arxiv.org/abs/1912.13515">arXiv</A> version)
mentioned before. This leads to the same IFO complexity
that matches SARAH-Compositional. At the same time, STORM-Compositional is a single loop algorithm that avoids typical
alternative tuning between large and small batch sizes, as well as recording of checkpoint gradients,
that persist in variance-reduced stochastic gradient methods.
This allows considerably simpler parameter tuning in numerical experiments, which demonstrates the
superiority of STORM-Compositional over other stochastic compositional optimization algorithms.
<P>
<b>Statement of Contribution of the work</b> [2]:
H. Yuan brought W. Hu's attention to this problem and participated in one small discussion when W. Hu raised the question
on the mini-batch sampling with replacement and another discussion about a question raised by W. Hu
regarding the missing bound in <A HREF="https://arxiv.org/abs/1912.13515">this work</A>,
the latter leading W. Hu to look at a relevant paper.
W. Hu performed all the mathematical proofs in [2] and worked on the experiment for Stochastic Neighbor Embedding.
W. Hu worked on the overall structure of the presentation and the write-up of the whole paper [2].
<P>
<b>Acknowledgement of the work</b> [2]:
The numerical experiments of [2] for portfolio management and reinforcement learning are done by
Dr. Jiaojiao Yang from Anhui Normal University, Wuhu, Anhui, P.R.China. Due to no initial involvement into
the project and upon graceful agreement with
J. Yang, she is not listed as an author of [2].
Still, W. Hu would like to thank J. Yang for the hard work in the numerical experiments.
<H4>Papers</H4>
[2] Yuan, H., <b>Hu, W.</b>, Stochastic Recursive Momentum Method for Non-Convex Compositional Optimization.
<A HREF="https://arxiv.org/abs/2006.01688">[arXiv]</A>
<A HREF="https://github.com/huwenqing0606/STORM-Compositional">[source code]</A>
<P>
[1] Yuan, H., Lian, X., Li, C.J., Liu, J., <b>Hu, W.</b>,
Efficient Smooth Non-Convex Stochastic Compositional Optimization via Stochastic Recursive Gradient Descent.
<i>NeurIPS 2019 (Thirty-third Conference on Neural Information Processing Systems), Vancouver, Canada, December 8-14, 2019</i>.
<A HREF="https://papers.nips.cc/paper/8916-efficient-smooth-non-convex-stochastic-compositional-optimization-via-stochastic-recursive-gradient-descent">[conference paper]</A>
</li>


<li><H3>Diffusion limit of stochastic approximation algorithms (e.g. stochastic gradient descent).</H3>
Many large-scale learning problems in modern statistics and machine learning can
be reduced to solving stochastic optimization problems, i.e., the search for (local) minimum
points of the expectation of an objective random function (loss function). These optimization
problems are usually solved by certain stochastic approximation algorithms,
which are recursive update rules with random inputs in each iteration. Under this project, we have been considering
various types of such stochastic approximation algorithms, including the stochastic
gradient descent, the stochastic composite gradient descent and the stochastic heavy-ball method.
By introducing approximating diffusion processes to the discrete recursive
schemes, we have analyzed the convergence of the diffusion limits to these algorithms via delicate techniques
in stochastic analysis and asymptotic methods. 
<H4>Papers</H4>
[4] <b>Hu, W.</b>, Li, C.J., Li, L., Liu, J., On the diffusion approximation of nonconvex stochastic gradient descent.
<i>Annals of Mathematical Science and Applications</i>, Vol. <b>4</b>, No. 1(2019), pp. 3-32.
<A HREF="https://arxiv.org/abs/1705.07562">[arXiv]</A>
<A HREF="https://www.intlpress.com/site/pub/pages/journals/items/amsa/content/vols/0004/0001/a001/index.html">[journal paper]</A>
<P>
[3] <b>Hu, W.</b>, Li, C.J., A convergence analysis of the perturbed compositional gradient flow: averaging principle and normal deviations.
<i>Discrete and Continuous Dynamical Systems, Series A</i>, <b>38</b>, 10, October 2018, pp. 4951-4977.
<A HREF="https://arxiv.org/abs/1709.00515">[arXiv]</A>
<A HREF="http://aimsciences.org/article/doi/10.3934/dcds.2018216">[journal paper]</A>
<P>
[2] <b>Hu, W.</b>, Li, C.J., Zhou, X., On the Global Convergence of Continuous-Time Stochastic Heavy-Ball Method for Nonconvex Optimization.
<i>IEEE Big Data 2019 (2019 IEEE International Conference on Big Data), Los Angeles, California, USA, December 9-12, 2019</i>.
<A HREF="https://arxiv.org/abs/1712.05733">[arXiv]</A>
<A HREF="https://ieeexplore.ieee.org/document/9005621">[conference paper]</A>
<P>
[1] Yang, J., <b>Hu, W.</b>, Li, C.J., On the fast convergence of random perturbations of the gradient flow.
<i>Asymptotic Analysis</i>, Volume <b>122</b>, 2021, pages 371-393.
<A HREF="https://arxiv.org/abs/1706.00837">[arXiv]</A>
<A HREF="paper_On_the_fast_convergence_of_random_perturbations_of_the_gradient_flow.pdf">[journal paper]</A>
<H4>Slides</H4>
[4] <A HREF="slides_Fast_convergence_random_perturbations_gradient_flow.pdf">
Fast convergence of random perturbations of the gradient flow</A>.
<P>
[3] <A HREF="slides_Perturbation_optimization.pdf">
A random perturbation approach to some stochastic approximation algorithms in optimization</A>.
<P>
[2] <A HREF="slides_SGD-Noise.pdf">
Some Probabilistic Understandings of the Effects of Noise in the Stochastic Gradient Descent</A>.
<P>
[1] <A HREF="slides_stochastic_approximation_perturbation.pdf">
Stochastic Approximations, Diffusion Limit and Small Random Perturbations of Dynamical Systems - a probabilistic approach to machine learning</A>.
</li>


<li><H3>Covariance matrix estimation under High-Dimensional-Low-Sample-Size (HDLSS) setting and regularized linear discriminant analysis.</H3>
Statistical estimation and inference under High-Dimensional-Low-Sample-Size (HDLSS) 
setting is one of the most challenging problems in the big data era. Under this 
research project, we propose various regularization methods using small size sample 
in the estimation of covariance matrices under high dimensional setting. These methods 
are then exploited to develop novel techniques in improving the inferential 
performance of the classical Fisher's Linear Discriminant Analysis (LDA), 
and concrete experiments are implemented on Electronic Health Records (EHR) dataset.
<H4>Papers</H4>
[4] Xiong, H., Cheng, W., Bian, J., <b>Hu, W.</b>, Sun, Z., Guo, Z.,
DBSDA: Lowering the Bound of Misclassification Rate for Sparse Linear Discriminant Analysis via Model Debiasing.
<i>IEEE Transactions on Neural Networks and Learning Systems</i>, Volume <b>30</b>, Issue 3, pp. 707-717, March 2019.
<A HREF="https://ieeexplore.ieee.org/document/8418814/">[journal paper]</A>
<P>
[3] Xiong, H., Cheng, W., Fu, Y., Bian, J., <b>Hu, W.</b>, Guo, Z.,
De-Biasing Covariance-Regularized Discriminant Analysis.
<i>IJCAI-ECAI 2018 (the 27th International Joint Conference on Artificial Intelligence and the 23rd European Conference on Artificial Intelligence),
Stockholm, Sweden, July 13-19, 2018</i>.
<A HREF="http://research.baidu.com/Public/uploads/5b0e46416fd41.pdf">[conference paper]</A>
<P>
[2] Bian, J., Xiong, H., Cheng, W., Fu, Y., <b>Hu, W.</b>, Guo, Z., Multi-Party Sparse Discriminant Learning.
<i>ICDM 2017 (2017 IEEE International Conference on Data Mining), New Orleans, Louisiana, USA, November 8-21, 2017</i>.
<A HREF="https://ieeexplore.ieee.org/document/8215549/">[conference paper]</A>
<P>
[1] Xiong, H., Cheng, W., Bian, J., <b>Hu, W.</b>, Guo, Z., AWDA: Adapted Wishart Discriminant Analysis.
<i>ICDM 2017 (2017 IEEE International Conference on Data Mining), New Orleans, Louisiana, USA, November 8-21, 2017</i>.
<A HREF="https://ieeexplore.ieee.org/document/8215525/">[conference paper]</A>
</li>


<li><H3>Multiscale Stochastic PDEs.</H3>
Stochastic partial differential equations of reaction-diffusion type have been 
introduced to model the spacial-temporal evolution of concentrations of various 
components in a chemical reaction. The stochastic noises are responsible for 
he random changes in space-time of the rates of reaction. As a rule, the 
rates of chemical reactions in the system and the diffusion coefficients 
have different orders. Some of them are much smaller than others and this 
leads to the consideration of stochastic reaction-diffusion equations with 
a separation of slow and fast scales, i.e. multiscale stochastic 
reaction-diffusion equations. Under this project, we consider for 
the first time the problem of large deviations for multiscale stochastic 
reaction-diffusion equations in multiple dimensions with multiplicative noise. 
<H4>Papers</H4>
[1] <b>Hu, W.</b>, Salins, M., Spiliopoulos, K., Large deviations and averaging for systems of slow-fast stochastic reaction-diffusion equations.
<i>Stochastics and  Partial Differential Equations: Analysis and Computations</i>, December 2019, Volume <b>7</b>, Issue 4, pp. 808-874.
<A HREF="https://arxiv.org/abs/1710.02618">[arXiv]</A>
<A HREF="https://link.springer.com/article/10.1007/s40072-019-00140-y">[journal paper]</A>
<P>
<H4>Slides</H4>
[2] <A HREF="slides_multiscale_SDE-SPDE.pdf">
Hypoelliptic multiscale Langevin diffusions and Slow-fast stochastic reaction-diffusion equations</A>.
<P>
[1] <A HREF="slides_LDP_Multiscale_SRDE.pdf">
Large deviations and averaging for systems of slow-fast reaction-diffusion equations</A>.
</li>


<li><H3>Two-dimensional stochastic fluid mechanics and turbulence models.</H3>
The famous canonical picture of 2-d turbulence due to Kraichnan
[Kraichnan, R.H., Inertial ranges in two dimensional turbulence, 
<i>Physics of Fluids</i>, <b>10</b>(7), pp. 1417-1423, 1967]
conjectures a dual cascade: an inverse energy cascade toward 
low Fourier modes (large scales) and a direct enstrophy cascade 
toward high Fourier modes (small scales), 
driven by the nonlinear interactions. 
In a series of groundbreaking works starting from
[Hairer, M., Mattingly, J. C., 
Ergodicity of the 2-d Navier-Stokes equations with degenerate stochastic forcing. 
<i>Annals of Mathematics</i> (2), <b>164</b>(3):993-1032, 2006],
unique ergodicity has been developed under the physically 
important case of a spatially degenerate (that is frequency localized) 
stochastic forcing.
In this project, we study problems of 2-d turbulence 
related to Kraichnan's conjectures from various geometric and dynamical perspectives.
We show (see our work [1] below) that if we consider 
the 2-d Navier-Stokes equations on the torus T^2 and we modify the viscous term to
damp all but finitely many modes, then all solutions converge in the 
long-time limit to a stationary solution to the 2-d Euler equation 
living on those finitely many modes.
Then one can classify those stationary solutions precisely. 
For example, if one removes damping from exactly two modes which are of
different frequency and in different directions (like sin(2x) and cos(y) for example), 
then solutions must choose one of the two modes and land only on one of them.
This "choice" happens through a non-linear process and it is unclear 
whether there are even statistics of which one is most likely chosen
(though, one expects that the stationary solution with the lowest 
frequency is generically chosen in the long-time limit).
To understand this non-linear process more thoroughly, 
we propose geometric approaches in our works [2] and [3] below, 
where we study finite-dimensional model problems
for the 2-d Navier-Stokes and Euler equations respecting 
their Hamiltonian and Lie-Poisson structures. We reveal mechanisms 
that lead to the interactions
of the nonlinearity, the stochastic noise and the partial dissipation. 
These interactions lead to novel long-time limit of the solutions.
<H4>Papers</H4>
[3] <b>Hu, W.</b>, On the long time behavior of a perturbed conservative system with degeneracy.
<i>Journal of Theoretical Probability</i>, Volume <b>33</b>, pp.1266-1295, 2020. (Published online on 11, May 2019.)
<A HREF="https://arxiv.org/abs/1808.01510">[arXiv]</A>
<A HREF="https://link.springer.com/article/10.1007/s10959-019-00911-2">[journal paper]</A>
<P>
[2] <b>Hu, W.</b>, Sverak, V., Dynamics of geodesic flows with random forcing on Lie groups with left-invariant metrics.
<i>Journal of Nonlinear Science</i>, <b>28</b>(6):2249-2274, December 2018.
<A HREF="http://arxiv.org/abs/1510.05279">[arXiv]</A>
<A HREF="https://link.springer.com/article/10.1007%2Fs00332-018-9446-1">[journal paper]</A>
<P>
[1] Elgindi, T., <b>Hu, W.</b>, Sverak, V., On 2d incompressible Euler equations with partial damping.
<i>Communications in Mathematical Physics</i>, <b>355</b>, Issue 1, October 2017, pp. 145-159.
<A HREF="http://arxiv.org/abs/1511.02530">[arXiv]</A>
<A HREF=" https://link.springer.com/article/10.1007/s00220-017-2877-y?wt_mc=Internal.Event.1.SEM.ArticleAuthorOnlineFirst">[journal paper]</A>
<H4>Slides</H4>
[5] <A HREF="slides_Stochastically_perturbed_geodesic_flows_on_Lie_groups.pdf">
Stochastically perturbed geodesic flows on Lie groups</A>.
<P>
[4] <A HREF="slides_2dEulerModel.pdf">
On 2d Euler equations with partial damping and some related model problems</A>.
<P>
[3] <A HREF="slides_perturbation-degenerate.pdf">
On the long time behavior of a perturbed conservative system with degeneracy</A>.
<P>
[2] <A HREF="slides_2-d_incompressible_Euler_equations_with_partial_damping.pdf">
2-d incompressible Euler equations with partial damping</A>.
<P>
[1] <A HREF="slides_Dynamics_of_geodesic_flows_with_random_forcing_on_Lie_groups_with_left_invariant_metrics.pdf">
Dynamics of geodesic flows with random forcing on Lie groups with left invariant metrics</A>.
</li>


<li><H3>Human mobility patterns via Hawkes processes.</H3>
The Hawkes process is a simple point process that has long memory, clustering effect, self-exciting property and is in general non-Markovian. The future evolution of a self-exciting point process is influenced by the timing of the past events. By making use of a multivariate Hawkes process (MHP) on a network, we characterize the human mobility patterns and discover the synchronization effect of trip purposes from real-world data.
<H4>Papers</H4>
[1] Wang, P., Liu, G., Fu, Y., <b>Hu, W.</b>, Aggarwal, C., Human Mobility Synchronization and Trip Purpose Detection with Mixture of Hawkes Processes. <i>KDD 2017 (Knowledge, Discovery and Data Mining), Halifax, Nova Scotia, Canada, August 13-17, 2017</i>. Accepted paper ID=fp1019.
<A HREF="http://dl.acm.org/citation.cfm?id=3098067">[conference paper]</A>
<A HREF="http://www.kdd.org/kdd2017/papers/view/human-mobility-synchronization-and-trip-purpose-detection-with-mixture-of-h">[abstract and video]</A>
</li>


<li><H3>Time Scales Stochastic Calculus.</H3>
A very initial attempt to develop stochastic calculus on time scales is made under 
this research topic. The results may shed some lights in the development of a 
mathematical theory of quantum Brownian motion (q-Brownian motion on a quantum time scale). 
<H4>Papers</H4>
[1] <b>Hu, W.</b>, Ito's formula, the stochastic exponential and change of measure on general time scales.
<i>Abstract and  Applied Analysis</i>, Vol. 2017, Article ID 9140138, 2017.
<A HREF="https://arxiv.org/abs/1609.05967">[arXiv]</A>
<A HREF="https://www.hindawi.com/journals/aaa/2017/9140138/">[journal paper]</A>
<H4>Slides</H4>
[1] <A HREF="slides_Ito_formula_general_time_scales.pdf">
Ito's formula on general time scales</A>.
</li>


<li><H3>Small mass limit of the Langevin equation (Smoluchowski-Kramers approximation).</H3>
The Langevin equation is one of the most classical models in stochastic calculus for the 
random motion of a particle suspended in a fluid. As a second-order stochastic 
differential equation, it describes the dynamics of a particle subject to a 
deterministic drift, a friction proportional to its velocity, as well as 
random fluctuations. The small-mass limit of this equation, sometimes also 
called the Smoluchowski-Kramers approximation, has been the main justification 
of using a first order stochastic differential equation to replace the original 
second-order equation. I have been considering variable and vanishing friction 
case of the Langevin equation, as well as a multiscale Langevin equation.
<H4>Papers</H4>
[3] <b>Hu, W.</b>, Spiliopoulos, K., Hypoelliptic multiscale Langevin diffusions: Large deviations, invariant measures and small mass asymptotics.
<i>Electronic Journal of Probability</i>, <b>22</b> (2017), paper no. 55, pp. 1-38.
<A HREF="http://arxiv.org/abs/1506.06181">[arXiv]</A>
<A HREF="http://projecteuclid.org/euclid.ejp/1498809677">[journal paper]</A>
<P>
[2] Freidlin, M., <b>Hu, W.</b>, Wentzell, A., Small mass asymptotic for the
motion with vanishing friction.
<i>Stochastic Processes and their Applications</i>, <b>123</b> (2013), pp. 45-75.
<A HREF="http://arxiv.org/abs/1201.1242">[arXiv]</A>
<A HREF="http://www.sciencedirect.com/science/article/pii/S0304414912001901">[journal paper]</A>
<P>
[1] Freidlin, M., <b>Hu, W.</b>, Smoluchowski-Kramers approximation in the case of variable friction.
<i>Journal of Mathematical Sciences</i>, <b>79</b>, 1, November 2011, translated from
<i>Problems in Mathematical Analysis</i>, <b>61</b>, October 2011 (in Russian).
<A HREF="http://arxiv.org/abs/1203.0603">[arXiv]</A>
<A HREF="http://www.springerlink.com/content/c077x0437u607430/ ">[journal paper]</A>
<H4>Slides</H4>
[2] <A HREF="slides_Hypoelliptic_multiscale_Langevin_diffusions.pdf">
Hypoelliptic multiscale Langevin diffusions</A>.
<P>
[1] <A HREF="slides_Small_mass_asymptotic_for_the_motion_with_variable_and_vanishing_friction.pdf">
Small mass asymptotic for the motion with variable and vanishing friction</A>.
</li>


<li><H3>Diffusion processes and asymptotic analysis of PDEs.</H3>
The close relation between the theory of second-order differential 
equations and Markov processes with continuous trajectories 
benefits each other. By making use of the averaging principle 
of diffusion processes, I analyzed the behavior of the 
solution to a second-order equation with an elliptic operator 
having a degenerate characteristic form, perturbed by another 
elliptic operator multiplied by a small parameter. 
<H4>Papers</H4>
[1] Freidlin, M., <b>Hu, W.</b>, On second order elliptic equations with a small parameter.
<i>Communications in Partial Differential Equations</i>, <b>38</b>, 10, 2013, pp. 1712-1736.
<A HREF="http://arxiv.org/abs/1203.5096">[arXiv]</A>
<A HREF="http://www.tandfonline.com/doi/abs/10.1080/03605302.2013.812658#.UiqeddJatIE">[journal paper]</A>
<H4>Slides</H4>
[1] <A HREF="slides_On_second_order_elliptic_equations_with_a_small_parameter.pdf">
Second order elliptic equations with a small parameter</A>.
</li>


<li><H3>Random perturbations of dynamical systems.</H3>
Dynamical systems with small random inputs are ubiquitous phenomena 
that appear in many scientific and engineering discipline. 
In the understanding of the time-evolution of a complex system, 
one chooses a relatively few number of major factors that govern the 
evolution of the system while neglecting other factors that are relatively 
insignificant. Due to the undetectable nature of these other factors 
being neglected, in a mathematical model they usually present themselves 
as random inputs. The random inputs can be included in some parameters 
that characterize the system, such as diffusion coefficients, rates 
of chemical reactions, time scales, etc. . Neglecting these random 
inputs is only effective in the case of finite time evolution. 
In fact, on long time scales, the factors which were considered as 
negligible, can become important and even critical for determining 
the system's behavior. By making use of large deviations theory and 
averaging principle, I have analyzed various model problems such as
small random perturbations of nearly-elastic mechanical system
(a.k.a. nearly-elastic billiard system), a generalization of 
the Landau-Lifschitz dynamics characterizing the magnetization 
dynamics in ferromagnetics, as well as dynamical systems with 
reflecting boundary conditions. In the work [5] done in the year 2018, 
I considered the long-time behavior of random perturbations of a 
degenerate system as an extension of the classical Freidlin-Wentzell theory. 
<H4>Papers</H4>
[5] <b>Hu, W.</b>, On the long time behavior of a perturbed conservative system with degeneracy.
<i>Journal of Theoretical Probability</i>, online.
<A HREF="https://arxiv.org/abs/1808.01510">[arXiv]</A>
<A HREF="https://link.springer.com/article/10.1007/s10959-019-00911-2">[journal paper]</A>
<P>
[4] <b>Hu, W.</b>, Tcheuko, L., Random perturbations of dynamical systems with reflecting boundary and corresponding PDE with a small parameter.
<i>Asymptotic Analysis</i>, <b>87</b>, 1-2, 2014, pp. 43-56.
<A HREF="http://arxiv.org/abs/1203.5092">[arXiv]</A>
<A HREF="http://content.iospress.com/articles/asymptotic-analysis/asy1197">[journal paper]</A>
<P>
[3] <b>Hu, W.</b>, On metastability in nearly-elastic systems.
<i>Asymptotic Analysis</i>, <b>79</b>, 1-2, 2012, pp. 65-86.
<A HREF="http://arxiv.org/abs/1202.0577">[arXiv]</A>
<A HREF="http://content.iospress.com/articles/asymptotic-analysis/asy1090">[journal paper]</A>
<P>
[2] Freidlin, M., <b>Hu, W.</b>, On perturbations of generalized Landau-Lifshitz dynamics.
<i>Journal of Statistical Physics</i>, <b>144</b>, 2011, pp. 978-1008.
<A HREF="http://arxiv.org/abs/1203.0602">[arXiv]</A>
<A HREF="http://www.springerlink.com/content/60110p1x4k8j2m65/">[journal paper]</A>
<P>
[1] Freidlin, M., <b>Hu, W.</b>, On stochasticity in nearly-elastic systems.
<i>Stochastics and Dynamics</i>, <b>12</b>, 3, 2012.
<A HREF="http://arxiv.org/abs/1203.5468">[arXiv]</A>
<A HREF="http://www.worldscientific.com/doi/abs/10.1142/S0219493711500201">[journal paper]</A>
<H4>Slides</H4>
[2] <A HREF="slides_perturbation-degenerate.pdf">
On the long time behavior of a perturbed conservative system with degeneracy</A>.
<P>
[1] <A HREF="slides_On_stochasticity_in_nearly-elastic_systems.pdf">
Stochastic behavior in nearly-elastic billiard systems</A>.
</li>

</ol>

<hr>
<P>Last updated: 01/2026</P>
</font>

</BODY>
</HTML>